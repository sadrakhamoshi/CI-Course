{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadrakhamoshi/CI-Course/blob/main/CI992_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBxPYfc0U22"
      },
      "source": [
        "# Your info\n",
        "\n",
        "Full name: Sadra Khamoshi \n",
        "\n",
        "Student ID: 97521261\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBD007b3-ntJ"
      },
      "source": [
        "# Q1. Hopfield"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAAR47H8-5ML"
      },
      "source": [
        "## Q1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV7Xa2Sx-6cV"
      },
      "source": [
        "# Q1.2_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your imports.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMIDe8oc_TLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c1a8da-6c9c-492d-eb3e-3321bb32f14b"
      },
      "source": [
        "# Q1.2_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your codes.\n",
        "\n",
        "patterns = np.array([[1, -1, 1, -1, 1, -1], [1, 1, 1, -1, -1, -1]])\n",
        "patterns_T = patterns.T\n",
        "weights = np.dot(patterns_T, patterns)\n",
        "np.fill_diagonal(weights, 0)\n",
        "print(f'weights : \\n {repr(weights)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights : \n",
            " array([[ 0,  0,  2, -2,  0, -2],\n",
            "       [ 0,  0,  0,  0, -2,  0],\n",
            "       [ 2,  0,  0, -2,  0, -2],\n",
            "       [-2,  0, -2,  0,  0,  2],\n",
            "       [ 0, -2,  0,  0,  0,  0],\n",
            "       [-2,  0, -2,  2,  0,  0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG9-OhaEYKHK",
        "outputId": "7a54b53f-c85f-47ed-b1ee-a4ffa41a857a"
      },
      "source": [
        "# Q1.2_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your codes.\n",
        "\n",
        "x = [-1, 1, 1, -1, -1, -1]\n",
        "\n",
        "def compute_new_x(x, index):\n",
        "        fire = np.sum(x*weights[index])\n",
        "        if fire >= 0:\n",
        "            x[index] = 1\n",
        "        else:\n",
        "            x[index] = -1\n",
        "        return x\n",
        "  \n",
        "last_x = np.copy(x)\n",
        "for i in range(1000):\n",
        "  x = compute_new_x(x, i % 6)\n",
        "  if (i + 1) % 6 == 0:\n",
        "      if np.array_equal(last_x, x):\n",
        "          break\n",
        "      last_x = np.copy(x)\n",
        "print(f'result : {repr(x)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result : [1, 1, 1, -1, -1, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMWCmByc-7H5"
      },
      "source": [
        "## Q1.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpWMwI6z--GX"
      },
      "source": [
        "# Q1.3_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your imports.\n",
        "from PIL import Image, ImageFont\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from pathlib import Path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTmDh0Tw_Tuy"
      },
      "source": [
        "# Q1.3_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your codes.\n",
        "# generate_data\n",
        "\n",
        "path = '/content/Pictures/'\n",
        "chars = 'ABCDEFGHIJ'\n",
        "fonts = [16, 32, 64]\n",
        "noises = [0.1, 0.3, 0.6]\n",
        "\n",
        "\n",
        "def generate_correct_data(threshold=0):\n",
        "    for f in fonts:\n",
        "        font = ImageFont.truetype('/content/tahoma.ttf', f)\n",
        "        images = {}\n",
        "        y_max =0\n",
        "        x_max =0 \n",
        "        for ch in chars:\n",
        "            im = Image.Image()._new(font.getmask(ch))\n",
        "            y, x = im.size\n",
        "            if x > x_max:\n",
        "                x_max = x\n",
        "            if y > y_max:\n",
        "                y_max = y\n",
        "            images[f'{ch}_{str(f)}'] = im        \n",
        "        \n",
        "        for k,v in images.items():\n",
        "            im_arr = np.array(v)\n",
        "            shape = im_arr.shape\n",
        "            offset_x = int((x_max - shape[0]) / 2)\n",
        "            offset_y = int((y_max - shape[1]) / 2)\n",
        "            \n",
        "            matrix_layout = np.zeros((x_max, y_max), dtype=\"uint8\")\n",
        "            matrix_layout[offset_x:offset_x + shape[0], offset_y:offset_y + shape[1]] = im_arr\n",
        "            \n",
        "            im_arr = matrix_layout\n",
        "            s = np.where(im_arr > 0 , 255, 0)\n",
        "            im_fixed = Image.fromarray(np.array(s,dtype=np.uint8))\n",
        "            im_fixed.save(f'{path}correct_data/{str(f)}/{k}.bmp')\n",
        "\n",
        "\n",
        "def add_noise_v2(img_arr, noise, fp, fontsize):\n",
        "    all_pixels = int(img_arr.shape[0]) * int(img_arr.shape[1])\n",
        "    noisy_pixels_num = int(all_pixels * noise)\n",
        "    noisy_image = np.copy(img_arr)\n",
        "    random_values = random.sample(range(0, all_pixels), noisy_pixels_num)\n",
        "\n",
        "    for val in random_values:\n",
        "        row = int(val / img_arr.shape[1])\n",
        "        col = int(val % img_arr.shape[1])\n",
        "        if img_arr[row][col] == 255:\n",
        "            noisy_image[row][col] = 0\n",
        "        else:\n",
        "            noisy_image[row][col] = 255\n",
        "\n",
        "    img = Image.fromarray(noisy_image, mode='L')\n",
        "    noise = int(noise * 100)\n",
        "    img.save(f'{path}noisy_data/{str(noise)}/{str(fontsize)}/{fp}')\n",
        "\n",
        "\n",
        "def generate_noisy_data(fontsize):\n",
        "    dir = os.listdir(f'/content/Pictures/correct_data/{str(fontsize)}')\n",
        "    for no in noises:\n",
        "        for fp in dir:\n",
        "            img = Image.open(f'/content/Pictures/correct_data/{str(fontsize)}/{fp}', mode='r')\n",
        "            img_arr = np.array(img)\n",
        "            add_noise_v2(img_arr, no, fp, fontsize)\n",
        "\n",
        "def generate_noise():\n",
        "    for f in fonts:\n",
        "        generate_noisy_data(f)\n",
        "\n",
        "def main():\n",
        "    # use below line to generate data without noise\n",
        "    generate_correct_data()\n",
        "\n",
        "    # use below line to generate data with noise\n",
        "    generate_noise()\n",
        "\n",
        "def create_directory():\n",
        "  if not os.path.isdir(f'{path}'):\n",
        "    for f in fonts:\n",
        "      os.makedirs(f'{path}correct_data/{str(f)}')\n",
        "\n",
        "  if not os.path.isdir(f'{path}noisy_data'):\n",
        "    for n in noises:\n",
        "      for f in fonts:\n",
        "        os.makedirs(f'{path}noisy_data/{str(int(n*100))}/{str(f)}')\n",
        "      os.makedirs(f'{path}noisy_data/results')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_directory()\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_77E3z22mDg",
        "outputId": "7cb9b6f0-29fc-4279-b963-b55e687cfcaf"
      },
      "source": [
        "# Q1.3_graded\n",
        "# Do not change the above line.\n",
        "\n",
        "# This cell is for your codes.\n",
        "# hopfield Netwrok\n",
        "\n",
        "class hopfield:\n",
        "    def __init__(self, n_num):\n",
        "        self.num = n_num\n",
        "        self.weights = np.zeros((n_num, n_num))\n",
        "\n",
        "    def train(self, patterns, types='bipolar'):\n",
        "        patterns_T = patterns.T\n",
        "        self.weights = np.dot(patterns_T, patterns)\n",
        "        np.fill_diagonal(self.weights, 0)\n",
        "        return\n",
        "\n",
        "    def compute_new_x(self, x, index):\n",
        "        fire = np.sum(x * self.weights[index])\n",
        "        if fire >= 0:\n",
        "            x[index] = 1\n",
        "        else:\n",
        "            x[index] = -1\n",
        "        return x\n",
        "\n",
        "    def async_update(self, x, max_itr=1000):\n",
        "        last_x = np.copy(x)\n",
        "        for i in range(max_itr):\n",
        "            x = self.compute_new_x(x, i % self.num)\n",
        "            if (i + 1) % self.num == 0:\n",
        "                if np.array_equal(last_x, x):\n",
        "                    return x\n",
        "                last_x = np.copy(x)\n",
        "        return x\n",
        "\n",
        "    def sync_update(self, x):\n",
        "        last_x = np.copy(x)\n",
        "        for i in range(1000):\n",
        "            x = self.restore(x)\n",
        "            if np.array_equal(x, last_x):\n",
        "                break\n",
        "            last_x = np.copy(x)\n",
        "        return x\n",
        "\n",
        "    def sign(self, t):\n",
        "        t = np.where(t >= 0, 1, -1)\n",
        "        return t\n",
        "\n",
        "    def restore(self, x):\n",
        "        t = np.sum(x * self.weights, axis=1)\n",
        "        return np.array(self.sign(t.T))\n",
        "\n",
        "    def evaluate_network(self, x):\n",
        "        return np.sign(np.dot(self.weights, x.T))\n",
        "\n",
        "\n",
        "def get_patterns():\n",
        "    patterns = []\n",
        "    dim1 = 48\n",
        "    dim2 = 50\n",
        "    images = os.listdir(f'New folder/images/')\n",
        "    for img in images:\n",
        "        tmp = Image.open(f'images/{img}', mode='r')\n",
        "        tmp = tmp.resize((dim1, dim2))\n",
        "        tmp = np.asarray(tmp, dtype=np.uint8)\n",
        "        pattern = -1 * np.ones(tmp.shape)\n",
        "        pattern[tmp > 60] = 1\n",
        "        patterns.append(pattern.flatten())\n",
        "    return np.array(patterns)\n",
        "\n",
        "\n",
        "def get_train_data(font):\n",
        "    patterns = []\n",
        "    path = f'/content/Pictures/correct_data/{str(font)}/'\n",
        "    files = os.listdir(path)\n",
        "    max_x = 0\n",
        "    max_y = 0\n",
        "    for file in files:\n",
        "        tmp = Image.open(f'{path}{file}', mode='r')\n",
        "        if tmp.size[1] > max_x:\n",
        "            max_x = tmp.size[1]\n",
        "        if tmp.size[0] > max_y:\n",
        "            max_y = tmp.size[0]\n",
        "        tmp.close()\n",
        "\n",
        "    for file in files:\n",
        "        tmp = Image.open(f'{path}{file}', mode='r')\n",
        "        img_array = tmp.resize((max_x, max_y))\n",
        "        img_array = np.asarray(img_array, dtype=np.uint8)\n",
        "        pattern = -1 * np.ones(img_array.shape)\n",
        "        pattern = np.where(img_array == 255, 1, -1)\n",
        "        patterns.append(pattern.flatten())\n",
        "    return np.array(patterns), (max_x, max_y)\n",
        "\n",
        "\n",
        "def get_train_data_v2(font):\n",
        "    patterns = []\n",
        "    path = f'/content/Pictures/correct_data/{str(font)}/'\n",
        "    files = os.listdir(path)\n",
        "    for file in files:\n",
        "        tmp = Image.open(f'{path}{file}', mode='r')\n",
        "        img_array = np.asarray(tmp, dtype=np.uint8)\n",
        "        pattern = -1 * np.ones(img_array.shape)\n",
        "        pattern = np.where(img_array == 255, 1, -1)\n",
        "        patterns.append(pattern.flatten())\n",
        "        ss = len(pattern.flatten())\n",
        "    return np.array(patterns)\n",
        "\n",
        "\n",
        "def evaluate_hopfield(hp: hopfield, noise, font , con):\n",
        "    acc_evaluate = []\n",
        "    acc_converge = []\n",
        "    path = f'/content/Pictures/noisy_data/{str(noise)}/{str(font)}/'\n",
        "    res_path = f'/content/Pictures/noisy_data/{str(noise)}/results/'\n",
        "    correct_data = f'/content/Pictures/correct_data/{str(font)}/'\n",
        "    files = os.listdir(path)\n",
        "    for file in files:\n",
        "        tmp = Image.open(f'{path}{file}', mode='r')\n",
        "        # img_array = tmp.resize((size[0], size[1]))\n",
        "        img_array = np.asarray(tmp, dtype=np.uint8)\n",
        "        shape = img_array.shape\n",
        "        pattern = -1 * np.ones(img_array.shape)\n",
        "        pattern = np.where(img_array == 255, 1, -1)\n",
        "        flatten_pattern = pattern.flatten()\n",
        "\n",
        "        fixed_img_arr = hp.evaluate_network(flatten_pattern)\n",
        "\n",
        "        converge = hp.sync_update(flatten_pattern)\n",
        "\n",
        "        fixed_img_arr = np.where(fixed_img_arr == 1, 255, 0)\n",
        "        fixed_img_arr = np.array(fixed_img_arr, dtype=np.uint8)\n",
        "\n",
        "        ## converge\n",
        "        converge = np.where(converge == 1, 255, 0)\n",
        "        converge = np.array(converge, dtype=np.uint8)\n",
        "\n",
        "        ## compute accuracy\n",
        "        correct_img = Image.open(f'{correct_data}{file}')\n",
        "        correct_img_arr = np.asarray(correct_img, dtype=np.uint8).flatten()\n",
        "        correctness = np.sum(fixed_img_arr == correct_img_arr)\n",
        "        acc_evaluate.append(correctness / len(correct_img_arr))\n",
        "\n",
        "        ## converge accuracy\n",
        "        correctness_con = np.sum(converge == correct_img_arr)\n",
        "        acc_converge.append(correctness_con / len(correct_img_arr))\n",
        "\n",
        "        res_img = Image.fromarray(fixed_img_arr.reshape(shape), mode='L')\n",
        "        res_img.save(f'{res_path}{str(noise)}_{file}')\n",
        "\n",
        "    print(\n",
        "        f'font : {font} , noise : {noise} ====> Evaluate accuracy : {np.mean(acc_evaluate)}'\n",
        "    )\n",
        "    con.append(f'font : {font} , noise : {noise} ====> Converge accuracy : {np.mean(acc_converge)}')\n",
        "\n",
        "\n",
        "def main():\n",
        "    fontsizes = [16, 32, 64]\n",
        "    noises = [10, 30, 60]\n",
        "    sizes = [11, 23, 45]\n",
        "    chars = 'ABCDEFGHIJ'\n",
        "    con = []\n",
        "\n",
        "    for font in fontsizes:\n",
        "        patterns = get_train_data_v2(font)\n",
        "        neurons = len(patterns[0])\n",
        "        hp = hopfield(int(neurons))\n",
        "        hp.train(patterns)\n",
        "        for noise in noises:\n",
        "            evaluate_hopfield(hp, noise, font, con)\n",
        "\n",
        "    print('convergence accuracy : ')\n",
        "    for c in con:\n",
        "        print(c)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "font : 16 , noise : 10 ====> Evaluate accuracy : 0.929861111111111\n",
            "font : 16 , noise : 30 ====> Evaluate accuracy : 0.9430555555555555\n",
            "font : 16 , noise : 60 ====> Evaluate accuracy : 0.1375\n",
            "font : 32 , noise : 10 ====> Evaluate accuracy : 0.9359683794466405\n",
            "font : 32 , noise : 30 ====> Evaluate accuracy : 0.9282608695652174\n",
            "font : 32 , noise : 60 ====> Evaluate accuracy : 0.09426877470355732\n",
            "font : 64 , noise : 10 ====> Evaluate accuracy : 0.9102990033222591\n",
            "font : 64 , noise : 30 ====> Evaluate accuracy : 0.900047460844803\n",
            "font : 64 , noise : 60 ====> Evaluate accuracy : 0.10783103939250119\n",
            "convergence accuracy : \n",
            "font : 16 , noise : 10 ====> Converge accuracy : 0.7402777777777778\n",
            "font : 16 , noise : 30 ====> Converge accuracy : 0.7402777777777778\n",
            "font : 16 , noise : 60 ====> Converge accuracy : 0.25972222222222224\n",
            "font : 32 , noise : 10 ====> Converge accuracy : 0.8446640316205534\n",
            "font : 32 , noise : 30 ====> Converge accuracy : 0.8031620553359684\n",
            "font : 32 , noise : 60 ====> Converge accuracy : 0.17490118577075098\n",
            "font : 64 , noise : 10 ====> Converge accuracy : 0.7585666824869483\n",
            "font : 64 , noise : 30 ====> Converge accuracy : 0.7578547698149027\n",
            "font : 64 , noise : 60 ====> Converge accuracy : 0.24214523018509732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRqYhKw1rgUp"
      },
      "source": [
        "# <font color='red'>Submission</font>\n",
        "\n",
        "1. Sign up in [Gradescope](https://www.gradescope.com) with proper name and student ID and use the following code to join the class: <font color='green'>**D5372R**</font>\n",
        "2. Fill in your full name (seperated by single spaces) and student ID in the beginning of this notebook.\n",
        "3. After you're done with this notebook, you should do the following:\n",
        "  - Clear all outputs of the notebook.\n",
        "  ![clear all outputs](https://i.ibb.co/y6FrttB/Screen-Shot-2021-03-21-at-01-51-42.png)\n",
        "  - Run all of the cells (if you skipped a question just leave the cell unchanged), and make sure all of your outputs are correct.\n",
        "  ![run all](https://i.ibb.co/cgRcBZ0/Screen-Shot-2021-03-21-at-01-54-58.png)\n",
        "  - Save your notebook.\n",
        "  - If you're using Colab, download your notebook.\n",
        "  ![download ipynb](https://i.ibb.co/2KxYM6K/Screen-Shot-2021-03-21-at-02-03-50.png)\n",
        "  - Put the notebook file you just downloaded and `convert.py` in the same folder run the following command:\n",
        "  ```bash\n",
        "  python convert.py\n",
        "  ```\n",
        "  This will export your code for each question into a `.py` file.\n",
        "    - **Note**: if you want to add more cells, add this to the **first** line of the cell:\n",
        "  ```python\n",
        "  # Q5_graded\n",
        "  ```\n",
        "  according to the question number.\n",
        "  - There are 2 assignments in Gradescope:\n",
        "\n",
        "    ![assignments](https://i.ibb.co/10GMhGM/Screen-Shot-2021-03-21-at-02-16-25.png)\n",
        "  \n",
        "    You should upload your **codes** and your **notebook** in `HW3` section and your final report for all of the questions as a **single pdf** file in `HW3 - Report`. Autograder will automatically check for:\n",
        "    - `CI992_HW3.ipynb`\n",
        "    - `Q1.2.py`\n",
        "    - `Q1.3.py`\n",
        "    - `inverted_pendulum.fcl`\n",
        "    - Your name and ID in the beginning of `.ipynb` file.\n",
        "\n",
        "    It is important that you <font color='red'>**don't**</font> change the names of these files before submission.\n",
        "\n",
        "4. If you pass the autograder, you're good to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ncvGuBu6f2e"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}